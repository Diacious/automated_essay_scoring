{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:03:30.011627Z","iopub.status.busy":"2024-06-03T09:03:30.010862Z","iopub.status.idle":"2024-06-03T09:04:03.599338Z","shell.execute_reply":"2024-06-03T09:04:03.598105Z","shell.execute_reply.started":"2024-06-03T09:03:30.011593Z"},"trusted":true},"outputs":[],"source":["!pip install \"./spellchecker/pyspellchecker-0.7.2-py3-none-any.whl\""]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-03T09:04:03.602040Z","iopub.status.busy":"2024-06-03T09:04:03.601666Z","iopub.status.idle":"2024-06-03T09:04:49.732840Z","shell.execute_reply":"2024-06-03T09:04:49.732060Z","shell.execute_reply.started":"2024-06-03T09:04:03.602007Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import os\n","import gc\n","import torch\n","import numpy as np\n","import re\n","import nltk\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","from datasets import Dataset\n","from transformers import Trainer, TrainingArguments\n","from pathlib import Path\n","from tqdm import tqdm\n","from lightgbm import LGBMClassifier\n","from gensim.parsing.preprocessing import remove_stopwords\n","from gensim.parsing.preprocessing import preprocess_string, strip_multiple_whitespaces, strip_numeric, strip_punctuation\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from nltk.corpus import stopwords\n","from spellchecker import SpellChecker"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Loading data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:04:49.734268Z","iopub.status.busy":"2024-06-03T09:04:49.733982Z","iopub.status.idle":"2024-06-03T09:04:50.736276Z","shell.execute_reply":"2024-06-03T09:04:50.735236Z","shell.execute_reply.started":"2024-06-03T09:04:49.734238Z"},"trusted":true},"outputs":[],"source":["train_data = Dataset.from_pandas(pd.read_csv(\"./learning-agency-lab-automated-essay-scoring-2/train.csv\"))\n","test_data = Dataset.from_pandas(pd.read_csv(\"./learning-agency-lab-automated-essay-scoring-2/test.csv\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:04:50.739135Z","iopub.status.busy":"2024-06-03T09:04:50.738333Z","iopub.status.idle":"2024-06-03T09:04:50.808273Z","shell.execute_reply":"2024-06-03T09:04:50.807495Z","shell.execute_reply.started":"2024-06-03T09:04:50.739109Z"},"trusted":true},"outputs":[],"source":["train_data_df = train_data.to_pandas()\n","test_data_df = test_data.to_pandas()"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Loading pre trained deberta model trained on same data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:04:50.809665Z","iopub.status.busy":"2024-06-03T09:04:50.809354Z","iopub.status.idle":"2024-06-03T09:04:50.815977Z","shell.execute_reply":"2024-06-03T09:04:50.815034Z","shell.execute_reply.started":"2024-06-03T09:04:50.809641Z"},"trusted":true},"outputs":[],"source":["# model on https://www.kaggle.com/datasets/diacious/deberta-scoring/settings\n","MODEL_PATH = \"./deberta-scoring/output/checkpoint-5188\"\n","MAX_LENGTH = 1024"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:06:40.225097Z","iopub.status.busy":"2024-06-03T09:06:40.224355Z","iopub.status.idle":"2024-06-03T09:06:52.771993Z","shell.execute_reply":"2024-06-03T09:06:52.771155Z","shell.execute_reply.started":"2024-06-03T09:06:40.225062Z"},"trusted":true},"outputs":[],"source":["labels = set(train_data['score'])\n","id2label = {l-1: l for l in labels}\n","label2id = {v: k for k, v in id2label.items()}\n","\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n","model =  AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n","#model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH,\n","#                                                          id2label=id2label,\n","#                                                          label2id=label2id,\n","#                                                         ignore_mismatched_sizes=True)\n","\n","id2label = model.config.id2label\n","label2id = model.config.label2id"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:06:58.256730Z","iopub.status.busy":"2024-06-03T09:06:58.256032Z","iopub.status.idle":"2024-06-03T09:06:58.261454Z","shell.execute_reply":"2024-06-03T09:06:58.260403Z","shell.execute_reply.started":"2024-06-03T09:06:58.256701Z"},"trusted":true},"outputs":[],"source":["def tokenize_texts(data):\n","    return tokenizer(data['full_text'],\n","                    max_length=MAX_LENGTH,\n","                    truncation=True,\n","                    padding='max_length',\n","                    #return_overflowing_tokens=True,\n","                    add_special_tokens = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:06:59.727403Z","iopub.status.busy":"2024-06-03T09:06:59.726564Z","iopub.status.idle":"2024-06-03T09:07:21.722512Z","shell.execute_reply":"2024-06-03T09:07:21.721514Z","shell.execute_reply.started":"2024-06-03T09:06:59.727363Z"},"trusted":true},"outputs":[],"source":["test_data_1 = test_data.map(tokenize_texts, batched=True)\n","train_data_1 = train_data.map(tokenize_texts, batched=True)\n","train_data_1 = train_data_1.rename_column('score', 'labels')\n","train_data_1 = train_data_1.map(lambda x: {'labels': x['labels'] - 1})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:07:21.724563Z","iopub.status.busy":"2024-06-03T09:07:21.724264Z","iopub.status.idle":"2024-06-03T09:07:21.730054Z","shell.execute_reply":"2024-06-03T09:07:21.729120Z","shell.execute_reply.started":"2024-06-03T09:07:21.724538Z"},"trusted":true},"outputs":[],"source":["def regulize_bert_params(model, freeze_layers=6, freeze_embedding=False):\n","    for param in model.deberta.embeddings.parameters():\n","            param.requires_grad = False if freeze_embedding else True\n","\n","    for layer in model.deberta.encoder.layer[:freeze_layers]:\n","        for param in layer.parameters():\n","            param.requires_grad = False\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:07:21.731599Z","iopub.status.busy":"2024-06-03T09:07:21.731279Z","iopub.status.idle":"2024-06-03T09:07:21.745071Z","shell.execute_reply":"2024-06-03T09:07:21.744271Z","shell.execute_reply.started":"2024-06-03T09:07:21.731571Z"},"trusted":true},"outputs":[],"source":["model = regulize_bert_params(model,\n","                             freeze_layers=24,\n","                             freeze_embedding=True)\n","model_base = model.base_model"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Getting features from deberta model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:16:30.604509Z","iopub.status.busy":"2024-06-03T09:16:30.603773Z","iopub.status.idle":"2024-06-03T09:16:30.620855Z","shell.execute_reply":"2024-06-03T09:16:30.619944Z","shell.execute_reply.started":"2024-06-03T09:16:30.604477Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.backends.cuda.is_built() else 'cpu'\n","model.to(device)\n","\n","model.eval()\n","def get_predictions(data):\n","    #model_base.eval()\n","    data = {k: v.to(device) for k, v in data.items()}\n","    \n","    with torch.no_grad():\n","        res = model(data['input_ids'], data['attention_mask'], data['token_type_ids']).logits\n","    #gc.collect()\n","    #torch.cuda.empty_cache()\n","    \n","    return {'deberta_out': res}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:16:32.234592Z","iopub.status.busy":"2024-06-03T09:16:32.234219Z","iopub.status.idle":"2024-06-03T09:16:37.793482Z","shell.execute_reply":"2024-06-03T09:16:37.792566Z","shell.execute_reply.started":"2024-06-03T09:16:32.234562Z"},"trusted":true},"outputs":[],"source":["test_data_2 = test_data_1.remove_columns(['essay_id', 'full_text'])\n","test_data_2.set_transform(lambda x: {k: torch.tensor(v) for k, v in x.items()})\n","\n","gc.collect()\n","torch.cuda.empty_cache()\n","test_data_3 = test_data_2.map(get_predictions, batched=True, batch_size=16)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:21:23.972540Z","iopub.status.busy":"2024-06-03T09:21:23.971747Z","iopub.status.idle":"2024-06-03T09:21:24.008990Z","shell.execute_reply":"2024-06-03T09:21:24.008102Z","shell.execute_reply.started":"2024-06-03T09:21:23.972506Z"},"trusted":true},"outputs":[],"source":["features_names = [f'deberta_feat_{i}' for i in range(6)]\n","\n","deberta_features_test = pd.DataFrame(test_data_1['essay_id'], columns=['essay_id'])\n","deberta_features_test[features_names] = test_data_3['deberta_out']\n","\n","deberta_features_train = pd.read_csv(\"./deberta_features/deberta_features_logits.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T08:29:12.589617Z","iopub.status.busy":"2024-06-03T08:29:12.586838Z","iopub.status.idle":"2024-06-03T08:29:12.614499Z","shell.execute_reply":"2024-06-03T08:29:12.613502Z","shell.execute_reply.started":"2024-06-03T08:29:12.589555Z"},"trusted":true},"outputs":[],"source":["deberta_features_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:21:25.858043Z","iopub.status.busy":"2024-06-03T09:21:25.857132Z","iopub.status.idle":"2024-06-03T09:21:25.870980Z","shell.execute_reply":"2024-06-03T09:21:25.869940Z","shell.execute_reply.started":"2024-06-03T09:21:25.858007Z"},"trusted":true},"outputs":[],"source":["deberta_features_test.head()"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Feature Engineering"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:21:45.121072Z","iopub.status.busy":"2024-06-03T09:21:45.120695Z","iopub.status.idle":"2024-06-03T09:24:41.685174Z","shell.execute_reply":"2024-06-03T09:24:41.684172Z","shell.execute_reply.started":"2024-06-03T09:21:45.121041Z"},"trusted":true},"outputs":[],"source":["text_transforms = [lambda x: x.lower(),\n","                   lambda x: re.sub(\"https?.+\", '',x),\n","                   lambda x: re.sub(r'<.*?>', '', x),\n","                   lambda x: x.replace(u'\\xa0',' '),\n","                   remove_stopwords, \n","                   strip_multiple_whitespaces, \n","                   strip_numeric, \n","                   strip_punctuation,\n","                   lambda x: x.strip()\n","                  ]\n","\n","def preprocess_text(text):\n","    for transform in text_transforms:\n","        text = transform(text)\n","    return text\n","\n","\n","def texts_preprocessing(df):\n","    df['full_text_pr'] = df['full_text'].apply(lambda x: preprocess_text(x))\n","    df['paragraphs'] = df['full_text'].apply(lambda x: x.split('\\n\\n'))\n","    df['sentences_per_par'] = df['paragraphs'].apply(lambda x: [sent_tokenize(par) for par in x])\n","    df['words_per_par'] = df['paragraphs'].apply(lambda x: [word_tokenize(preprocess_text(par)) for par in x])\n","    df['words_per_par_all'] = df['paragraphs'].apply(lambda x: [word_tokenize(par) for par in x])\n","    \n","    df['sentences_per_par'] = df['sentences_per_par'].apply(lambda x: [[preprocess_text(sent) for sent in par] for par in x])\n","    \n","stopwords_set = set(stopwords.words('english'))\n","statistics_func = [('max', max), ('min', min), ('mean', np.mean)]\n","spellchecker = SpellChecker()\n","\n","def make_features(df):\n","    texts_features = pd.DataFrame()\n","    \n","    texts_features['text_len'] = df['full_text_pr'].apply(lambda x: len(x))\n","\n","    texts_features['punct_count'] = df['full_text'].apply(lambda x: len(re.findall(r'[^\\w\\s]', x)))\n","    texts_features['punct_count_per_par'] = df['paragraphs'].apply(lambda x: [len(re.findall(r'[^\\w\\s]', par)) for par in x])\n","    \n","    texts_features['sentences_count'] = df['sentences_per_par'].apply(lambda x: sum([len(par) for par in x]))\n","    texts_features['sentences_count_per_par'] = df['sentences_per_par'].apply(lambda x: [len(par) for par in x])\n","    \n","    texts_features['words_count'] = df['words_per_par'].apply(lambda x: sum([len(par) for par in x]))\n","    texts_features['words_count_per_par'] = df['words_per_par'].apply(lambda x: [len(par) for par in x])\n","    \n","    texts_features['paragraphs_len'] = df['paragraphs'].apply(lambda x: [len(par) for par in x])\n","    texts_features['paragraphs_count'] = df['paragraphs'].apply(lambda x: len(x))\n","    \n","    texts_features['words_len_all'] = df['words_per_par'].apply(lambda x: [len(word) for par in x if len(par) > 0 for word in par])\n","    texts_features['sentences_len_all'] = df['sentences_per_par'].apply(lambda x: [len(sent) for par in x for sent in par])\n","    \n","    texts_features['n_unique_words'] = df['words_per_par'].apply(lambda x: len(set([word for par in x for word in par])))\n","    texts_features['n_stopwords'] = df['words_per_par_all'].apply(lambda x: sum([word in stopwords_set for par in x for word in par]))\n","    texts_features['n_misspelled_words'] = df['words_per_par'].apply(lambda x: len(spellchecker.unknown([word for par in x for word in par])))\n","    \n","    for func_name, func in statistics_func:\n","        texts_features[f'punct_count_per_par_{func_name}'] = texts_features['punct_count_per_par'].apply(func)\n","        texts_features[f'sentences_len_{func_name}'] = df['sentences_per_par'].apply(lambda x: func([len(sent) for par in x for sent in par]))\n","        texts_features[f'sentences_count_{func_name}'] = df['sentences_per_par'].apply(lambda x: func([len(par) for par in x]))\n","        texts_features[f'words_len_{func_name}'] = df['words_per_par'].apply(lambda x: func([len(word) for par in x for word in par]))\n","        texts_features[f'words_count_{func_name}'] = df['words_per_par'].apply(lambda x: func([len(par) for par in x]))\n","        texts_features[f'paragraphs_len_{func_name}'] = df['paragraphs'].apply(lambda x: func([len(par) for par in x]))\n","        \n","    return texts_features\n","\n","\n","texts_preprocessing(train_data_df)\n","texts_preprocessing(test_data_df)\n","\n","texts_features_train = make_features(train_data_df)\n","texts_features_test = make_features(test_data_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:24:41.687227Z","iopub.status.busy":"2024-06-03T09:24:41.686954Z","iopub.status.idle":"2024-06-03T09:24:44.378907Z","shell.execute_reply":"2024-06-03T09:24:44.378062Z","shell.execute_reply.started":"2024-06-03T09:24:41.687204Z"},"trusted":true},"outputs":[],"source":["punct_bound = [10, 25, 40, 55, 75, 90, 100]\n","sentence_count_bounds = [5, 15, 20, 25, 30, 35, 50]\n","sentence_len_bounds = [20, 50, 60, 74, 85, 100, 1000]\n","words_count_bounds = [80, 100, 150, 200, 400, 500]\n","paragraphs_len_bounds = [30, 100, 300, 450, 550, 1000, 1500]\n","words_len_bounds = [5, 7, 9, 12, 20]\n","\n","bounds = [punct_bound,\n","         sentence_count_bounds,\n","         words_count_bounds,\n","         paragraphs_len_bounds,\n","         words_len_bounds,\n","         sentence_len_bounds]\n","\n","col_names = [('punct_per_par_bound', 'punct_count_per_par'),\n","            ('sentences_count_per_par_bound', 'sentences_count_per_par'),\n","            ('words_count_per_par_bound', 'words_count_per_par'),\n","            ('paragraphs_len_bound', 'paragraphs_len'),\n","            ('words_len_all_bound', 'words_len_all'),\n","            ('sentences_len_all_bound', 'sentences_len_all')]\n","\n","\n","def get_features_bounds(df, name, col, bounds):\n","    for i in range(len(bounds)):\n","        lower_bound = bounds[i - 1] if i - 1 >= 0 else 0\n","        upper_bound = bounds[i]\n","        \n","        df[f'{name}_{lower_bound}_{upper_bound}'] = df[col].apply(lambda x: sum([1 for el in x if lower_bound < el <= upper_bound]))\n","        \n","    df[f'{name}_{bounds[-1]}'] = df[col].apply(lambda x: sum([1 for el in x if  el > bounds[-1]]))\n","        \n","def get_paragraphs_features(features):\n","    for (name, col), bound in zip(col_names, bounds):\n","        get_features_bounds(features, name, col, bound)\n","\n","    features = features.drop([col[1] for col in col_names], axis=1)\n","    return features \n","    \n","    \n","texts_features_train = get_paragraphs_features(texts_features_train)\n","texts_features_test = get_paragraphs_features(texts_features_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:24:44.380299Z","iopub.status.busy":"2024-06-03T09:24:44.380011Z","iopub.status.idle":"2024-06-03T09:24:52.378719Z","shell.execute_reply":"2024-06-03T09:24:52.377750Z","shell.execute_reply.started":"2024-06-03T09:24:44.380274Z"},"trusted":true},"outputs":[],"source":["from nltk.probability import FreqDist\n","\n","def get_prob_cum_sum(df):\n","    fdist = FreqDist(word for essay in df['words_per_par'].to_list() for par in essay for word in par)\n","\n","    cum_sum = []\n","\n","    for i, pair in enumerate(sorted(fdist.items(), key=lambda x: x[1])):\n","        if cum_sum:\n","            cum_sum.append((pair[0], cum_sum[i - 1][1] + fdist.freq(pair[0])))\n","        else:\n","            cum_sum.append((pair[0], fdist.freq(pair[0])))\n","\n","    cum_sum_dict = dict(cum_sum)\n","    \n","    return cum_sum_dict\n","\n","words_freq_bounds = [0.05, 0.2, 0.5, 0.75, 0.95, 1]\n","def add_freq_bounds(df, features, cum_sum):\n","    for i in range(len(words_freq_bounds)):\n","        upper_bound = words_freq_bounds[i]\n","        lower_bound = words_freq_bounds[i - 1] if i - 1 >= 0 else 0\n","\n","        features[f'num_words_lower_{lower_bound}_{upper_bound}'] = df['words_per_par'].apply(lambda x: sum([1 for par in x for word in par if lower_bound < cum_sum.get(word, 0) <= upper_bound]))\n","        \n","        \n","cum_sum = get_prob_cum_sum(train_data_df)\n","add_freq_bounds(train_data_df, texts_features_train, cum_sum)\n","add_freq_bounds(test_data_df, texts_features_test, cum_sum)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:24:52.380861Z","iopub.status.busy":"2024-06-03T09:24:52.380571Z","iopub.status.idle":"2024-06-03T09:24:52.410722Z","shell.execute_reply":"2024-06-03T09:24:52.409937Z","shell.execute_reply.started":"2024-06-03T09:24:52.380837Z"},"trusted":true},"outputs":[],"source":["texts_features_train['essay_id'] = train_data_df['essay_id']\n","texts_features_train = texts_features_train.merge(deberta_features_train, on='essay_id', how='inner')\n","\n","\n","texts_features_test['essay_id'] = test_data_df['essay_id']\n","texts_features_test = texts_features_test.merge(deberta_features_test, on='essay_id', how='inner')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:25:20.132327Z","iopub.status.busy":"2024-06-03T09:25:20.131970Z","iopub.status.idle":"2024-06-03T09:25:20.160734Z","shell.execute_reply":"2024-06-03T09:25:20.159944Z","shell.execute_reply.started":"2024-06-03T09:25:20.132302Z"},"trusted":true},"outputs":[],"source":["texts_features_train['score'] = train_data_df['score']\n","texts_features_train = texts_features_train.drop(['essay_id'], axis=1)\n","\n","texts_features_test = texts_features_test.drop(['essay_id'], axis=1)\n","texts_features_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:25:27.257918Z","iopub.status.busy":"2024-06-03T09:25:27.257135Z","iopub.status.idle":"2024-06-03T09:26:59.945146Z","shell.execute_reply":"2024-06-03T09:26:59.944065Z","shell.execute_reply.started":"2024-06-03T09:25:27.257863Z"},"trusted":true},"outputs":[],"source":["stopwords_list = stopwords.words('english')\n","tf_idf_char_level = TfidfVectorizer(\n","            tokenizer=lambda x: x,\n","            preprocessor=lambda x: x,\n","            token_pattern=None,\n","            strip_accents='unicode',\n","            analyzer = 'word',\n","            ngram_range=(1,3),\n","            min_df=0.05,\n","            max_df=0.95,\n","            sublinear_tf=True,\n",")\n","\n","tf_idf_word_level_clened_text = TfidfVectorizer(\n","    strip_accents='ascii',\n","    analyzer = 'word',\n","    ngram_range=(1,1),\n","    min_df=0.15,\n","    max_df=0.85,\n","    sublinear_tf=True,\n","    stop_words=stopwords_list,\n",")\n","\n","tf_idf_word_level_full_text = word_vectorizer = TfidfVectorizer(\n","    strip_accents='ascii',\n","    analyzer = 'word',\n","    ngram_range=(1,1),\n","    min_df=0.03,\n","    max_df=0.95,\n","    sublinear_tf=True\n",")\n","\n","X_chars = tf_idf_char_level.fit_transform(train_data_df['full_text'])\n","X_words_full = tf_idf_word_level_full_text.fit_transform(train_data_df['full_text'])\n","X_words_cleaned = tf_idf_word_level_clened_text.fit_transform(train_data_df['full_text_pr'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:26:59.947515Z","iopub.status.busy":"2024-06-03T09:26:59.946798Z","iopub.status.idle":"2024-06-03T09:27:01.764870Z","shell.execute_reply":"2024-06-03T09:27:01.763947Z","shell.execute_reply.started":"2024-06-03T09:26:59.947487Z"},"trusted":true},"outputs":[],"source":["df_chars = pd.DataFrame(X_chars.toarray())\n","df_words = pd.DataFrame(X_words_full.toarray())\n","df_words_cleaned = pd.DataFrame(X_words_cleaned.toarray())\n","\n","tfid_w_columns = [f'tfid_w_{i}' for i in range(len(df_words.columns))]\n","tf_idf_w_cl_columns = [f'tfid_w_cl_{i}' for i in range(len(df_words_cleaned.columns))]\n","\n","df_words.columns = tfid_w_columns\n","df_words_cleaned.columns = tf_idf_w_cl_columns\n","\n","data = pd.concat((df_chars, df_words, df_words_cleaned, texts_features_train), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:27:01.766451Z","iopub.status.busy":"2024-06-03T09:27:01.766132Z","iopub.status.idle":"2024-06-03T09:27:01.807298Z","shell.execute_reply":"2024-06-03T09:27:01.806178Z","shell.execute_reply.started":"2024-06-03T09:27:01.766424Z"},"trusted":true},"outputs":[],"source":["X_chars_test = tf_idf_char_level.transform(test_data_df['full_text'])\n","X_words_full_test = tf_idf_word_level_full_text.transform(test_data_df['full_text'])\n","X_words_cleaned_test = tf_idf_word_level_clened_text.transform(test_data_df['full_text_pr'])\n","\n","df_chars_test = pd.DataFrame(X_chars_test.toarray())\n","df_words_test = pd.DataFrame(X_words_full_test.toarray())\n","df_words_cleaned_test = pd.DataFrame(X_words_cleaned_test.toarray())\n","\n","tfid_w_columns_test = [f'tfid_w_{i}' for i in range(len(df_words_test.columns))]\n","tf_idf_w_cl_columns_test = [f'tfid_w_cl_{i}' for i in range(len(df_words_cleaned_test.columns))]\n","\n","df_words_test.columns = tfid_w_columns_test\n","df_words_cleaned_test.columns = tf_idf_w_cl_columns_test\n","\n","test_data = pd.concat((df_chars_test, df_words_test, df_words_cleaned_test, texts_features_test), axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-02T18:46:03.878986Z","iopub.status.busy":"2024-06-02T18:46:03.878516Z","iopub.status.idle":"2024-06-02T18:46:03.907665Z","shell.execute_reply":"2024-06-02T18:46:03.906045Z","shell.execute_reply.started":"2024-06-02T18:46:03.878934Z"},"trusted":true},"outputs":[],"source":["test_data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T08:41:39.111066Z","iopub.status.busy":"2024-06-03T08:41:39.110591Z","iopub.status.idle":"2024-06-03T08:41:39.143831Z","shell.execute_reply":"2024-06-03T08:41:39.142580Z","shell.execute_reply.started":"2024-06-03T08:41:39.111023Z"},"trusted":true},"outputs":[],"source":["data.head()"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Trainning lgb model on custom loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:27:01.810245Z","iopub.status.busy":"2024-06-03T09:27:01.809937Z","iopub.status.idle":"2024-06-03T09:27:01.815513Z","shell.execute_reply":"2024-06-03T09:27:01.814238Z","shell.execute_reply.started":"2024-06-03T09:27:01.810220Z"},"trusted":true},"outputs":[],"source":["from lightgbm import LGBMClassifier, LGBMRegressor\n","import lightgbm as lgb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:27:01.817504Z","iopub.status.busy":"2024-06-03T09:27:01.817085Z","iopub.status.idle":"2024-06-03T09:27:01.828099Z","shell.execute_reply":"2024-06-03T09:27:01.827198Z","shell.execute_reply.started":"2024-06-03T09:27:01.817469Z"},"trusted":true},"outputs":[],"source":["# loos from  https://www.kaggle.com/code/rsakata/optimize-qwk-by-lgb/notebook#QWK-objective\n","def quadratic_weighted_kappa(y_true, y_pred):\n","    y_true = (y_true + a).round()\n","    y_pred = (y_pred + a).clip(1, 6).round()\n","    qwk = cohen_kappa_score(y_true, y_pred, weights=\"quadratic\")\n","    return 'QWK', qwk, True\n","\n","def qwk_obj(y_true, y_pred):\n","    labels = y_true + a\n","    preds = y_pred + a\n","    preds = preds.clip(1, 6)\n","    f = 1/2*np.sum((preds-labels)**2)\n","    g = 1/2*np.sum((preds-a)**2+b)\n","    df = preds - labels\n","    dg = preds - a\n","    grad = (df/g - f*dg/g**2)*len(labels)\n","    hess = np.ones(len(labels))\n","    return grad, hess\n","\n","def qwk_param_calc(y):\n","    a = y.mean()\n","    b = (y ** 2).mean() - a**2\n","    return np.round(a, 4), np.round(b, 4)\n","\n","a = 2.998\n","b = 1.092"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:27:01.829696Z","iopub.status.busy":"2024-06-03T09:27:01.829372Z","iopub.status.idle":"2024-06-03T09:32:30.288563Z","shell.execute_reply":"2024-06-03T09:32:30.287473Z","shell.execute_reply.started":"2024-06-03T09:27:01.829669Z"},"trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, cohen_kappa_score\n","from sklearn.model_selection import StratifiedGroupKFold, StratifiedKFold\n","\n","callbacks = [\n","    lgb.log_evaluation(period=25), \n","    lgb.early_stopping(stopping_rounds=200,first_metric_only=True)\n","]\n","\n","models = []\n","skf = StratifiedKFold(n_splits=5, shuffle=True)\n","\n","for train_idx, val_idx in skf.split(data.iloc[:, :-1], data.iloc[:, -1]):\n","    #print(train_idx.shape, val_idx.shape)\n","    X_train, y_train = data.iloc[train_idx, :-1], data.iloc[train_idx, -1]\n","    X_val, y_val = data.iloc[val_idx, :-1], data.iloc[val_idx, -1]\n","    \n","    y_train -= a\n","    y_val -= a\n","\n","    model = LGBMRegressor(\n","            objective = qwk_obj, metrics = 'None', learning_rate = 0.1, max_depth = 5,\n","            num_leaves = 10, colsample_bytree=0.5, reg_alpha = 0.1, reg_lambda = 0.8,\n","            n_estimators=1024, verbosity = - 1\n","        )\n","\n","    lgb_model = model.fit(\n","            X_train, y_train,\n","            eval_names=['train', 'valid'],\n","            eval_set=[(X_train, y_train), (X_val, y_val)],\n","            eval_metric=quadratic_weighted_kappa,\n","            callbacks=callbacks\n","        )\n","    \n","    models.append(lgb_model)"]},{"cell_type":"markdown","metadata":{},"source":["# 6. Making predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:32:30.290862Z","iopub.status.busy":"2024-06-03T09:32:30.290551Z","iopub.status.idle":"2024-06-03T09:32:30.388996Z","shell.execute_reply":"2024-06-03T09:32:30.387944Z","shell.execute_reply.started":"2024-06-03T09:32:30.290819Z"},"trusted":true},"outputs":[],"source":["preds = []\n","for _, model in enumerate(models):\n","    pred = model.predict(test_data) + a\n","    preds.append(pred)\n","\n","# Combining the 5 model results\n","for i, pred in enumerate(preds):\n","    test_data[f\"score_pred_{i}\"] = pred\n","test_data_df[\"score\"] = np.round(test_data[[f\"score_pred_{fold}\" for fold in range(5)]].mean(axis=1),0).astype('int32')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:32:30.390497Z","iopub.status.busy":"2024-06-03T09:32:30.390211Z","iopub.status.idle":"2024-06-03T09:32:30.400552Z","shell.execute_reply":"2024-06-03T09:32:30.399623Z","shell.execute_reply.started":"2024-06-03T09:32:30.390472Z"},"trusted":true},"outputs":[],"source":["test_data_df[[\"essay_id\", \"score\"]].to_csv(\"submission.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-03T09:32:30.401811Z","iopub.status.busy":"2024-06-03T09:32:30.401564Z","iopub.status.idle":"2024-06-03T09:32:31.073165Z","shell.execute_reply":"2024-06-03T09:32:31.072233Z","shell.execute_reply.started":"2024-06-03T09:32:30.401789Z"},"trusted":true},"outputs":[],"source":["importances = lgb_model.feature_importances_\n","feature_importances = pd.Series(importances, index=data.iloc[:, :-1].columns, name='Features Importance').sort_values()\n","feature_importances.iloc[-20:].to_frame().plot.barh(figsize=(10, 10))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":8059942,"sourceId":71485,"sourceType":"competition"},{"datasetId":3596984,"sourceId":6258399,"sourceType":"datasetVersion"},{"datasetId":4981928,"sourceId":8397975,"sourceType":"datasetVersion"},{"datasetId":5139432,"sourceId":8591955,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
